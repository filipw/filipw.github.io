<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Advanced RAG patterns for AI Applications</title>
    <meta name="description" content="">
    <meta name="author" content="Filip W">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <script src="//code.jquery.com/jquery-1.8.0.js"></script>
    <script src="//code.jquery.com/ui/1.8.23/jquery-ui.js"></script>
    <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/js/bootstrap.min.js"></script>
    <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/css/bootstrap-combined.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.11.0/styles/default.min.css">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/simple.css" id="theme">
    <link rel="stylesheet" href="css/monokai_sublime.css" />
    <link rel="stylesheet" href="css/custom.css" />
    <script src="fsharp.formatting/styles/tips.js" type="text/javascript"></script>
    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">
    <!-- If the query includes 'print-pdf', include the PDF print sheet -->

    <script>
        if (window.location.search.match(/print-pdf/gi)) {
            var link = document.createElement('link');
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = 'css/print/pdf.css';
            document.getElementsByTagName('head')[0].appendChild(link);
        }
    </script>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
    <style type="text/css">
    </style>
</head>

<body>
    <div class="reveal">
        <header
            style="position: absolute;top: 50px; left: 100px; z-index:500; font-size:100px;background-color: rgba(0,0,0,0.5)">
        </header>
        <!-- Any section element inside of this container is displayed as a slide -->
        <div class="slides">

            <section data-background="images/greg-rakozy-oMpAz-DN-9I-unsplash.jpg">

                <div class="col overlay-style" style="padding: 0 !important">

                    <h1 style="font-size: 2em; background: none; margin-bottom: 0;">
                        Advanced RAG patterns<br />
                        <small style="font-size: 0.5em; line-height: 2em;">for AI Applications</small>
                    </h1>
                    <p style="margin-top: 0; padding-bottom: 20px;">
                        <small>
                            <a href="https://strathweb.com" class="roll">
                                <span>strathweb.com</span>
                            </a> •
                            <a href="https://mathstodon.xyz/filipw" class="roll">
                                <span data-title="@filip_woj">@filipw@mathstodon.xyz</span>
                            </a> •
                            <a href="https://github.com/filipw" class="roll">
                                <span data-title="github.com/filipw">Filip W</span>
                            </a>
                        </small>
                    </p>
                </div>

            </section>

            <section data-background-color="#fff">
                <img src="images/sonova.png" style="min-height: auto" />
            </section>


                                                <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="overlay-style">
                        <p>
                            But Filip, no one cares about RAG anymore. It's now all about
                        </p>
                        <h2 class="r-fit-text">AI Agents!</h2>
                    </div>
                </section>

                                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">

                        <div class="column-container">
                            <div class="col-50">
                                <p>An <span class="highlight">AI Agent</span> is fundamentally a system that combines knowledge (from training data, RAG, or other sources) with tools (APIs, search, databases, etc.) to autonomously perform tasks and achieve goals in dynamic environments.</p><p>In this session we will focus on the <span class="highlight">knowledge</span> aspect</p>
                            </div>
                            <div class="col-50" style="padding-left: 1em;">
                                <div class="img-backdrop">
                                    <img src="images/ai-agent.png" class="standard" style="min-height: auto;" />
                                </div>

                            </div>
                        </div>

                    </div>
                </section>

            <!-- Background -->
            <section>
                <section data-background="images/growtika-nGoCBxiaRO0-unsplash.jpg">
                    <h1>Background</h1>
                </section>
                <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="overlay-style">
                        <p>
                            Language models can be thought of as being purely functional
                        </p>
                        <h3 class="r-fit-text">$f: \{in:[uint]\} \rightarrow \{out:[uint]\}$</h3>
                        <p>where the input is a sequence of tokens and the output is a sequence of tokens.</p>
                    </div>
                </section>

                                <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="overlay-style">
                        <p>
                            Since we can map an array of tokens as a string, we could further simplify this to
                        </p>
                        <h3 class="r-fit-text">$f: \{in: str\} \rightarrow \{out: str\}$</h3>
                    </div>
                </section>

                <!-- <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="overlay-style">
                        <p>
                            <img src="images/model-assistant.png" class="standard" />
                        </p>
                        <p>But how do we arrive at such experience then?</p>

                    </div>
                </section>

                <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="overlay-style">
                        <p>During "assistant fine-tuning", by training on conversation samples, the model learns to</p>
                        <h2 class="r-fit-text">recognize special tokens</h2>
                        <p>such as <span class="highlight">&lt;|user|&gt;</span>, <span
                                class="highlight">&lt;|assistant|&gt;</span> or <span
                                class="highlight">&lt;|system|&gt;</span>, enabling role-based interactions and dialogue
                            handling.</p>
                    </div>
                </section>

                <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="overlay-style">$f : \{in: str\} \rightarrow \{out: str\}$
                    </div>

                    <div class="column-container">
                        <div>
                            <pre>
                <code class="nohighlight rounded">
<|system|>
You are ChatGPT, an AI language model designed to assist with a wide variety of tasks, answering questions, providing explanations, helping with creative projects, technical challenges and user issues. Be friendly and helpful.
<|end|>

<|user|>Hello! Who are you?<|end|>
<|assistant|>
                </code>
            </pre>
                        </div>
                        <div>

                            <pre>
                <code class="nohighlight rounded">
Hello! I'm ChatGPT, an AI language model designed to assist with a wide variety of tasks, from answering questions and providing explanations to helping with creative projects and technical challenges. How can I help you today?<|end|>
                </code>
            </pre>
                        </div>
                    </div>
                </section> -->

                <!-- <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="column-container">
                        <div class="col-33">
                            <div class="overlay-style">
                                <p>LLMs are</p>
                                <h2 class="r-fit-text">stateless</h2>
                                <p>They do not retain memory of past interactions. To maintain context in a series of
                                    interactions, the <span class="highlight">entire</span> relevant history must be
                                    <span class="highlight">included</span> with each subsequent query.
                                </p>
                            </div>
                        </div>
                        <div class="col-66">

                            <pre>
                <code class="nohighlight rounded">
<|system|>
You are a pirate, designed to assist with a wide variety of tasks. You are helpful.
<|end|>

<|user|>Hi, who are you?<|end|>
<|assistant|>
Arrr! Avast ye, matey! I be ChatGPT the pirate, scourge o' the digital seas. How can I be assistin' ye on this fine day? ☠️🏴‍☠️<|end|>
<|user|>My name is Filip, refer to me by name.<|end|>
<|assistant|>
Aye, Filip! What be yer next question, matey? 🏴‍☠️<|end|>
<|user|>Write a poem about quantum mechanics.<|end|>
<|assistant|>
                </code>
            </pre>
                        </div>
                    </div>
                    <p class="fragment" data-code-focus="2-7"></p>
                    <p class="fragment" data-code-focus="8"></p>
                    <p class="fragment" data-code-focus="2-10"></p>
                    <p class="fragment" data-code-focus="11"></p>
                    <p class="fragment" data-code-focus="2-14"></p>
                </section> -->



                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <div>
                            Given this functional nature of the models, there
                            are only two options to get our data into the model.</div>
                        <hr />
                        <ul>
                            <li class="fragment" style="margin: 0;">🛠️ inject our information into the internals of the model<br/>
                                <small>→ fine-tuning</small>
                            </li>
                            <li class="fragment" style="margin: 0;">🗣️ find creative ways of generating the input string<br/>
                                <small>→ RAG</small>

                            </li>
                        </ul>
                    </div>
                </section>

                                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <div class="column-container" style="align-items: flex-end;">
                            <div class="col">
                                <img src="images/books-hi.png" class="standard" />

                            </div>
                            <div class="col">
                                <br />
                                <img src="images/books-lo.png" class="standard" />
                            </div>

                        </div>
                        <p>LLMs are a "blurry JPEG" of their training data.</p>
                    </div>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">

                        <div class="column-container">
                            <div class="col-50">
                                <p><span
                                        class="highlight">Retrieval-Augmented Generation</span> (RAG) concept was first introduced in 2020¹ and remains the primary technique for grounding AI models in facts and addressing the hallucination problems.</span></p>
                            </div>
                            <div class="col-50" style="padding-left: 1em;">
                                <div class="img-backdrop">
                                    <img src="images/rag-paper.png" class="standard" style="min-height: auto;" />
                                </div>

                            </div>
                        </div>
                                                <div>
                                                    <p></p>
                        <p class="footnote">
¹ Lewis et al., Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. https://arxiv.org/abs/2005.11401
                        </p >
                        </div>
                    </div>
                </section>



                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                                            <div class="img-backdrop">
                    <img src="graphics/rag-basic.excalidraw.png" class="standard" style="max-height: 600px;" />

                        </div>
                    <p class="overlay-style" style="padding: 1% !important;">Naive RAG</p>
                </section>

<section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
    <div class="overlay-style">
        <h2>Why Naive RAG Fails</h2>
        <div class="column-container">
            <div class="col">
                <ul>
                    <li class="fragment">🗂️ <strong>Poor Data Preparation</strong><br />
                        <small>→ Raw HTML, unstructured content, noise<br />
                            → No metadata or contextual enrichment</small>
                    </li>
                    <li class="fragment">🎯 <strong>Query-Document Mismatch</strong><br />
                        <small>→ "Best hearing aid?" vs technical specifications<br />
                            → Semantic similarity breaks down</small>
                    </li>
                </ul>
            </div>
            <div class="col">
                <ul>
                    <li class="fragment">🔍 <strong>Inefficient Retrieval</strong><br />
                        <small>→ Searches entire corpus every time<br />
                            → No query optimization or routing logic</small>
                    </li>
                    <li class="fragment">💰 <strong>Cost & Performance Issues</strong><br />
                        <small>→ Processing thousands of irrelevant tokens<br />
                            → High latency and compute costs</small>
                    </li>
                </ul>
            </div>
        </div>
        <!-- <div class="fragment">
            <hr />
            <p>This session → <strong>Advanced patterns</strong> that systematically address each failure mode</p>
        </div> -->
    </div>
</section>



            </section> <!-- end Background -->

            <!-- Pre-Retrieval Optimization-->
            <section>
                <section data-background="images/max-langelott-wWQ760meyWI-unsplash.jpg">
                    <h1>Pre-Retrieval Optimization</h1>
                </section>

                <section data-background="images/michael-dziedzic-nbW-kaz2BlE-unsplash.jpg">
                    <div class="overlay-style">
                        <div>
                                <p>How the data is chunked and indexed can significantly impact the quality of the results. <span class="highlight">Chunking optimization</span> is a key factor in improving retrieval performance.
                            </p>
                        </div>
                        <div class="img-backdrop">
                            <img src="graphics/info-density2.excalidraw.png" />
                        </div>
                    </div>
                </section>
<!-- 
<section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
    <div class="overlay-style">
        <h3>Pre-Retrieval Optimization</h3>
        <div class="column-container">
            <div class="col">
                <ul>
                    <li class="fragment">🤖 <strong>LLM-Assisted Data Preparation</strong><br />
                        <small>→ Intelligent content cleaning<br />
                            → token reduction and metadata extraction</small>
                    </li>
                    <li class="fragment">🏗️ <strong>Multi-Level Index Architecture</strong><br />
                        <small>→ Hierarchical filtering with document summaries<br />
                            → Eliminate noise from irrelevant documents</small>
                    </li>
                </ul>
            </div>
            <div class="col">
                <ul>
                    <li class="fragment">🎯 <strong>Query-Document Alignment</strong><br />
                        <small>→ Bridge asymmetry between questions and content<br />
                            → Hypothetical embeddings for better matching</small>
                    </li>
                    <li class="fragment">⚙️ <strong>Adaptive Chunking Strategies</strong><br />
                        <small>→ Dynamic boundaries based on content type<br />
                            → Optimize for both precision and context</small>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</section> -->

                                <section data-background="images/michael-dziedzic-nbW-kaz2BlE-unsplash.jpg">
 <div class="overlay-style">
        <h3>LLM-Assisted Content Preprocessing Pipeline</h3>
        <hr />
        <div>
            <p>Clean and standardize source content while extracting <span class="highlight">rich metadata</span>. Chunks with contextual information improve retrieval accuracy.</p>
        </div>
 <div class="img-backdrop">
 <img class="standard" src="graphics/content-processing.excalidraw.png" style="max-height: 400px;" />
 </div>
 </div>
</section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Information Density Optimization</h3>
                        <hr />
                        <div class="column-container">
                            <div class="col-33" style="display: block;">
                                <p>Raw Product Page</p>
                                <pre style="font-size: 0.33em;"><code>
&lt;html lang="en-US"&gt;
&lt;script async="" src="https://..."&gt;
&lt;div class="nav-menu"&gt;Choose another country...
&lt;div class="cookie-banner"&gt;
AI Noise Cancelling Hearing Aid
Phonak Audéo Sphere™ Infinio
Dedicated AI Chip | Universal connectivity...
                </code></pre>
                            </div>
                            <div class="col-33" style="display: block;">
                                <p>Stripped Content</p>
                                <pre style="font-size: 0.33em;"><code>
AI Noise Cancelling Hearing Aid
Phonak Audéo Sphere Infinio
Dedicated AI Chip Universal connectivity
Go Charging Being in the moment
exceptional speech clarity
Offering exceptional speech clarity
from any direction filters out noise
speech allowing engage friends family...
                </code></pre>
                            </div>
                            <div class="col-33" style="display: block;">
                                <p>LLM Processed</p>
                                <pre style="font-size: 0.33em;"><code>
The Phonak Audéo Sphere Infinio features 
the world's first dedicated AI chip 
(DEEPSONIC) for hearing aids. It provides 
exceptional speech clarity from any 
direction with 10dB SNR improvement, 
universal connectivity, and go charging 
technology for all-day reliability.
                </code></pre>
                            </div>
                        </div>
                        <div class="column-container">

                            <div class="col-33">18 000 tokens</div>
                            <div class="col-33"> 1 400 tokens</div>
                            <div class="col-33"> 220 tokens</div>
                        </div>
                        <p class="fragment">82x <span class="highlight">reduction</span> in tokens with higher <span
                                class="highlight">information density</span></p>
                    </div>
                </section>

                <!-- TODO: Sample-->

                <section data-background="images/michael-dziedzic-nbW-kaz2BlE-unsplash.jpg">
 <div class="overlay-style">
 <h3>Hierarchical Index Retrieval</h3>
 <hr />
 <div>
 <p>Two-stage document filtering: search <span class="highlight">document summaries</span> first, then search chunks from <span class="highlight">relevant documents only</span>. Eliminates noise from irrelevant documents early.</p>
 </div>
 <div>
 <img class="standard" src="graphics/hi.excalidraw.png" />
 </div>
 <div style="clear:both;">
 <p class="footnote" style="text-align: center;">Liu, Y. et al. "Dense Hierarchical Retrieval for Open-Domain Question Answering" EMNLP Findings (2021)
 </p>
 </div>
 </div>
</section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Hypothetical Prompt Embeddings (HyPE)</h3>
                        <hr />
                        <div>
                            <p>Transforms question-document retrieval into question-question matching.
                                Up to <span class="highlight">42%</span> improvement in retrieval precision¹.</p>

                        </div>
                        <div>
                            <img class="standard" src="graphics/hype2.excalidraw.png" />
                        </div>
                        <div style="clear:both;">
                            <p class="footnote" style="text-align: center;">¹ Vake, Domen and Vičič, Jernej and Tošić, Aleksandar, Bridging the Question-Answer Gap in Retrieval-Augmented Generation: Hypothetical Prompt Embeddings. http://dx.doi.org/10.2139/ssrn.5139335
                            </p>
                        </div>
                    </div>
                </section>

                <!-- <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <img src="images/flows-rag-v3.png" class="standard" style="max-height: none;" />
                    <p class="overlay-style" style="padding: 1% !important;">Retrieval Augmented Generation</p>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <img src="images/flows-rag-rewrite-v3.png" class="standard" style="max-height: 600px;" />
                    <p class="overlay-style" style="padding: 1% !important;">RAG with Query Rewrite</p>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Embeddings</h3>

                        <div class="column-container">
                            <div class="col-66" style="padding: 3%; padding-top: 0;">
                                <p>Information can be encoded into <span class="highlight">highly dimensional
                                        vectors</span> called embeddings.</p>
                                <p>Related ones can then be found by performing mathematical operations between the
                                    vectors, such as cosine similarity or dot product.</p>
                            </div>
                            <div class="col-33">
                                <br />
                                <img src="images/vectors.png" class="standard" />
                            </div>
                        </div>
                    </div>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <img src="images/flows-rag-embeddings-v3.png" class="standard" style="max-height: 600px;" />
                    <p class="overlay-style" style="padding: 1% !important;">RAG with Query Rewrite & Embeddings</p>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <img src="images/flows-rag-embeddings-function-v3.png" class="standard"
                        style="max-height: 600px;" />
                    <p class="overlay-style" style="padding: 1% !important;">RAG with Query Rewrite, Embeddings &
                        Functions</p>
                </section> -->
            </section><!-- Pre-Retrieval Optimization -->

            <section>
                <section data-background="images/hao-wang-pVq6YhmDPtk-unsplash.jpg">
                    <div class="col overlay-style" style="padding: 0 !important">

                        <h1>Advanced Retrieval</h1>
                        </h1>
                    </div>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Conversational Query Optimization</h3>
                        <hr />
                        <div class="column-container">
                            <div class="col-66">
                                <img src="graphics/rag-with-qrw.excalidraw.png" class="standard"
                                    style="max-height: 600px;" />

                            </div>
                            <div class="col-33">

                                <ul style="font-size: 0.8em">
                                    <li>❌ Using just "What's the battery life like?"<br /> <small>→ Too vague</small>
                                    </li>
                                    <li>❌ Using entire conversation<br /> <small>→ Includes irrelevant AI chip
                                            details</small></li>
                                    <li>✅ LLM-generated optimal search query<br /> <small>"Phonak Audéo Sphere Infinio
                                            battery life
                                            and charging specifications"</small></li>
                                </ul>

                            </div>
                        </div>
                </section>

                                <section data-background="images/maxime-valcarce-mAj8xn5zXsk-unsplash.jpg">
                    <div class="overlay-style">
                        <div class="column-container">
                            <div class="col-66">
                                <div class="img-backdrop">
                                    <img src="images/gen-query-rewriting.png" style="min-height: auto;" />
                                </div>
                            </div>
    
                            <div class="col-33" style="padding: 3%; padding-top: 0;">
                                <div>
                                <p>SLM query rewriting is now an integral feature of</p>
                                <h2 class="r-fit-text">Azure AI Search</h2>
                                </div>
                            </div>
                        </div>
    
                    </div>
                </section>

                <section data-background="images/michael-dziedzic-nbW-kaz2BlE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Hypothetical Document Embeddings (HyDE)</h3>
                        <hr />
                        <div>
                            <p>If the index contains detailed, verbose documents, then embedding over a <span class="highlight">hypothetical response</span> can produce better results than embedding a pure user query.</p>
                        </div>
                        <div>
                            <img class="standard" src="graphics/hyde2.excalidraw.png" />
                        </div>
                        <div style="clear:both;">
                            <p class="footnote" style="text-align: center;">Gao, L. et al. "Precise Zero-Shot Dense Retrieval without Relevance Labels" arXiv:2212.10496 (2022)
                            </p>
                        </div>
                    </div>
                </section>
                <!-- TODO: HyDE code? -->

<section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
 <div class="overlay-style">
 <table class="medium">
 <colgroup>
 <col style="width: 28%;">
 <col style="width: 36%;">
 <col style="width: 36%;">
 </colgroup>
 <thead>
 <tr>
 <th></th>
 <th>🔍 HyDE<br /><small>(Hypothetical Document Embeddings)</small></th>
 <th>❓ HyPE<br /><small>(Hypothetical Prompt Embeddings)</small></th>
 </tr>
 </thead>
 <tbody>
 <tr>
 <td><strong>Strategy</strong></td>
 <td>Generate hypothetical answer</td>
 <td>Generate hypothetical questions</td>
 </tr>
 <tr>
 <td><strong>When Applied</strong></td>
 <td>Query time (search phase)</td>
 <td>Index time (preprocessing phase)</td>
 </tr>
  <tr>
 <td><strong>Semantic Matching</strong></td>
 <td>Document-to-Document</td>
 <td>Question-to-Question</td>
 </tr>
 <tr>
 <td><strong>Process</strong></td>
 <td>Query → Hypothetical response → Embed → Search</td>
 <td>Document → Question set → Embed → Index</td>
 </tr>
 <tr>
 <td><strong>Best For</strong></td>
 <td>Verbose, detailed document collections</td>
 <td>Question-answer format datasets</td>
 </tr>
 </tbody>
 </table>
 <div style="clear:both;">
 <p class="footnote" style="text-align: center;">
 HyDE transforms <strong>queries</strong>, HyPE transforms <strong>documents</strong>
 </div>
 </div>
</section>



                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Query Routing</h3>
                        <hr />
                                <p>Route query to most appropriate source or skip RAG completely</p>

                        <div class="column-container">
                            <div class="col-66">
                                <img src="graphics/rag-with-routing3.excalidraw.png" class="standard"
                                    style="max-height: 600px;" />

                            </div>
                            <div class="col-33">
                                <ul style="font-size: 0.8em">
                                    <li>❌ Skip Retrieval<br /> <small>→ "Explain that more simply"</small>
                                    </li>
                                    <li>✅ Product Spec RAG<br /> <small>→ "What AI chip does it use?"</small></li>
                                    <li>✅ User Guide RAG<br /> <small>→ "How do I pair my device?"</small></li>
                                </ul>

                            </div>
                        </div>
                </section>

                <section data-background="images/michael-dziedzic-nbW-kaz2BlE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Self-Reflection RAG</h3>
                        <hr />
                        <div>
                            <p>Self-RAG is a technique in which language models are fine-tuned to generate <span class="highlight">critique tokens</span> alongside responses, enabling them to <span class="highlight">self-assess</span> when to retrieve information and evaluate their own output.</p>
                        </div>
                        <div class="img-backdrop" style="margin-bottom: 20px;">
                            <img class="standard" src="graphics/selfrag2.excalidraw.png" />
                        </div>

                        <div style="clear:both;">
                            <p class="footnote" style="text-align: center;">Asai, A. et al. "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection" arXiv:2310.11511 (2023)
                            </p>
                        </div>
                    </div>
                </section>

<!-- <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
 <div class="overlay-style">
 <h3>Self-RAG Reflection Tokens</h3>
 <div class="column-container">
 <div class="col">
 <ul>
 <li class="fragment">🔄 <strong>Retrieval Control</strong><br />
 <small><code>[Retrieve]</code> - Fetch external info<br />
 <code>[No Retrieval]</code> - Continue without sources</small>
 </li>
 <li class="fragment">✅ <strong>Relevance Assessment</strong><br />
 <small><code>[Relevant]</code> - Passage is useful<br />
 <code>[Irrelevant]</code> - Passage doesn't help</small>
 </li>
 </ul>
 </div>
 <div class="col">
 <ul>
 <li class="fragment">📋 <strong>Support Verification</strong><br />
 <small><code>[Fully Supported]</code> - Backed by evidence<br />
 <code>[No Support]</code> - Claims lack backing</small>
 </li>
 <li class="fragment">⭐ <strong>Utility Evaluation</strong><br />
 <small><code>[Utility:5]</code> - Highly useful response<br />
 <code>[Utility:1]</code> - Low utility response</small>
 </li>
 </ul>
 </div>
 </div>
 <div class="fragment">
 <hr />
 <p><strong>Important!</strong> Self-RAG requires a fine-tuned model that learns to generate "reflection tokens"!</p>
 </div>
 </div>
</section> -->

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <p>There is a related technique called <span class="highlight">RAFT</span>
                            (retrieval-augmented fine tuning), which is based on the idea of teaching the model how
                            to
                            use documentation.</p>
                        <p>
                            <img src="images/raft.png" class="standard" style="min-height: auto;" />
                        </p>
                        <div style="clear:both;">
                            <p class="footnote" style="text-align: center;">Tianjun Zhang, Shishir G. Patil, Naman
                                Jain,
                                Sheng Shen, Matei Zaharia, Ion Stoica, Joseph E. Gonzalez - "RAFT: Adapting Language
                                Model to Domain Specific RAG" (2023). https://doi.org/10.48550/arXiv.2403.10131.
                                (image
                                from the paper)
                            </p>
                        </div>
                    </div>
                </section>
</section>

            <section>
                <section data-background="images/maria-teneva-7FmSYQ3Z7fg-unsplash.jpg">
                    <h1>Emerging Patterns</h1>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <div class="column-container">
                            <div class="col-33">
                                <div class="img-backdrop">
                                    <img src="images/graphrag.png" style="min-height: auto;" />
                                </div>
                            </div>
                            <div class="col-66">
                                <p><br />GraphRAG allows extracting a <span class="highlight">knowledge graph</span>
                                    out
                                    of a corpus of data, building a hierarchy, generating summaries for them, and
                                    then
                                    leveraging these structures when performing RAG.</p>
                            </div>
                        </div>
                        <div style="clear:both;"><br />
                            <p class="footnote" style="text-align: center;">Darren Edge and Ha Trinh and Newman
                                Cheng
                                and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Jonathan
                                Larson -
                                "From Local to Global: A Graph RAG Approach to Query-Focused Summarization.
                                https://arxiv.org/abs/2404.16130.
                            </p>
                        </div>
                    </div>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <img src="images/graphrag-diagram.png" class="standard" style="max-height: 600px;" />
                    <p class="overlay-style" style="padding: 1% !important;">Knowledge graph RAG</p>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <p>Models with <span class="highlight">realtime audio</span> interfaces can also be used with
                            RAG-patterns, allowing for audio conversations grounded in data.</p>
                        <div class="img-backdrop">
                            <img src="images/voicerag.png" class="standard" style="max-height: 300px;" />
                        </div>
                    </div>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <div class="column-container">
                            <div class="col-50">
                                <div class="img-backdrop">
                                    <img src="graphics/toolcalling3.excalidraw.png" style="min-height: auto;" />
                                </div>
                            </div>
                            <div class="col-50">
                                <p>Tool-calling is an essential feature of any agentic AI system. However, research shows that agents with many tools to choose, get <span class="highlight">overwhelmed</span> easily and their performance can degrade significantly¹.</p>
                            </div>
                        </div>
                        <div style="clear:both;"><br />
                            <p class="footnote" style="text-align: center;">¹ Weiwen Liu et al. "ToolACE: Winning the Points of LLM Function Calling." arXiv:2409.00920, September 2024.
                            </p>
                        </div>
                    </div>
                </section>

                                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <h3>Contextual Function Selection</h3>
                        <div class="column-container">
                            <div class="col-50">
 <p>Microsoft's Semantic Kernel addresses this by using RAG to dynamically filter and present only the <span class="highlight">most relevant tools</span> based on conversation context, reducing token consumption and improving response accuracy.</p>
 </div>
                            <div class="col-50">
                                <div class="img-backdrop">
                                    <img src="graphics/toolcalling-rag.excalidraw.png" style="min-height: auto;" />
                                </div>
                            </div>

                        </div>
                        <div style="clear:both;"><br />
                            <p class="footnote" style="text-align: center;">Microsoft. (2024). Smarter SK Agents with Contextual Function Selection. Microsoft Developer Blog.
                            </p>
                        </div>
                    </div>
                </section>

                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <div class="overlay-style">
                        <p>Embeddings can be used to represent any type of data!</p>
                        <hr />
<p>
    <span class="emoji">🏞️</span> image <span class="arrow">→</span> <span class="emoji">🧠</span> image model <span class="arrow">→</span> <span class="emoji">🔢</span> float vector <br/>
    <span class="emoji">🎧</span> audio <span class="arrow">→</span> <span class="emoji">🧠</span> audio model <span class="arrow">→</span> <span class="emoji">🔢</span> float vector <br/>
    <span class="emoji">📝</span> text <span class="arrow">→</span> <span class="emoji">🧠</span> text model <span class="arrow">→</span> <span class="emoji">🔢</span> float vector <br/>
</p>
                    </div>
                </section>

                                <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                    <img src="graphics/image-rag2.excalidraw.png" class="standard" style="max-height: 600px;" />
                    <p class="overlay-style" style="padding: 1% !important;">Image-based RAG</p>
                </section>

            </section>

            <section data-background="images/all.png">
            </section>

            <section data-background="images/and-machines-2yClsTFXIcE-unsplash.jpg">
                <div class="overlay-style">
                    <h2>Thank you</h2>
                    <div class="column-container centered">
                        <div class="col auto">
                            <img class="small" src="images/thankyou.gif" style="min-height: auto; margin:0" />
                        </div>
                        <div class="col auto">
                            <ul style="font-size: 0.9em;">
                                <li>📝 <a
                                        href="https://filipw.github.io/dotnetday-zurich-2025">filipw.github.io/dotnetday-zurich-2025</a>
                                </li>
                                <li>🖥️ <a
                                        href="https://github.com/filipw/2025-switzerland-netday-demos">github.com/filipw/2025-switzerland-netday-demos</a>
                                </li>
                                <li>📸 <a href="http://unsplash.com">Photos credit: Unsplash</a></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </section>

            <section data-background-color="#000">
                <img src="images/bye.gif" />
            </section>

        </div>
    </div>
    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
        </script>
    <script>
        // Full list of configuration options available here:
        // https://github.com/hakimel/reveal.js#configuration

        Reveal.initialize({
            viewDistance: 30,
            controls: true,
            progress: true,
            history: true,
            center: true,
            keyboard: {
                39: 'next', // Right Arrow
                37: 'prev'  // Left Arrow
            },
            transition: 'slide', // default/cube/page/concave/zoom/linear/fade/none

            // Parallax scrolling
            // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
            // parallaxBackgroundSize: '2100px 900px',

            // Optional libraries used to extend on reveal.js
            dependencies: [
                { src: 'lib/js/classList.js', condition: function () { return !document.body.classList; } },
                { src: 'plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
                { src: 'plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
                { src: 'plugin/highlight.js/highlight.pack.js', async: true, callback: function () { /*hljs.initHighlightingOnLoad();*/ } },
                { src: 'plugin/zoom-js/zoom.js', async: true, condition: function () { return !!document.body.classList; } },
                { src: 'plugin/notes/notes.js', async: true, condition: function () { return !!document.body.classList; } },
                { src: 'plugin/alt-arrows/alt-arrows.js' },
                {
                    src: 'plugin/reveal-code-focus.js',
                    async: true,
                    callback: function () {
                        RevealCodeFocus();
                    }
                }
            ]
        });

        // Reveal.configure({
        //     keyboard: {
        //         39: 'next', // Right Arrow
        //         37: 'prev'  // Left Arrow
        //     }
        // });

    </script>
</body>

</html>